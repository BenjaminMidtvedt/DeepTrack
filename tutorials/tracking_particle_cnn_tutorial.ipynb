{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepTrack - Tracking a point particle with a CNN\n",
    "\n",
    "This notebook demonstrates how to track point particles with a convolutional neural network using DeepTrack.\n",
    "\n",
    "Specifically, this tutotial explains how to: \n",
    "* Define the procedure to generate training images\n",
    "* Extract information from images to use as labels\n",
    "* Define and train a neural network model\n",
    "* Visually evaluate the quality of the neural network output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "Imports needed for this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deeptrack.scatterers import PointParticle\n",
    "from deeptrack.optics import OpticalDevice\n",
    "from deeptrack.generators import Generator\n",
    "from deeptrack.models import convolutional\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define the particle\n",
    "\n",
    "For this example, we consider a point particle (i.e. a point light scatterer). A point particle is an instance of the class PointParticle, defined by its intensity and its position\n",
    "\n",
    "A point particle is controlled by the following parameters:\n",
    "\n",
    "* intensity: The intensity of the point particle\n",
    "\n",
    "* position: The position of the point particle\n",
    "\n",
    "* position_unit: \"pixel\" or \"meter\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_particle = PointParticle(                                         \n",
    "    intensity=100,\n",
    "    position=(32, 16),\n",
    "    position_unit=\"pixel\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define the optics \n",
    "\n",
    "Next, we need to define the properties of the optical system. This is done using an instance of the class Optics, which takes a set of light scatterers (particles) and convolves them with the pupil function (point spread function) of the optical system. In this tutorial, there is only one light scatterer (here, `point_particle`).\n",
    "\n",
    "The optics is controlled by the following parameters:\n",
    "\n",
    "* NA: The numerical aperature\n",
    "\n",
    "* pixel_size: The pixel to meter conversion factor (m/px)\n",
    "\n",
    "* wavelength: The wavelength of the lightsource (m)\n",
    "\n",
    "* mode: \"coherent\" or \"incoherent\" light emitted by the object\n",
    "\n",
    "* ROI: Region of interest that is imaged (to avoid wrap-around effects when Fourier-tranforming)\n",
    "\n",
    "* upscale: upscale factor for the pupil function (increases accuracy and computational cost)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optics = OpticalDevice(\n",
    "    NA=0.7,                \n",
    "    pixel_size=0.1e-6,     \n",
    "    wavelength=680e-9\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create and plot the image\n",
    "\n",
    "To view some object through an optical device, we call the optical device (here, `optics`), with the object we want to image (here, `point_particle`). This creates a new object (here, `imaged_particle`) that can be used to generate the desired image.\n",
    "\n",
    "The image is finally generated by calling `imaged_particle.resolve(input_image)`, where `input_image` is an numpy array of the desired image shape (this can be seen as the background image)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imaged_particle = optics(point_particle)\n",
    "\n",
    "input_image = np.zeros((64, 64))\n",
    "output_image = imaged_particle.resolve(input_image)\n",
    "\n",
    "plt.imshow(output_image, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Randomize the particle position\n",
    "\n",
    "We can generate particles with random positions by passing to the keyword argument `position` a lambda function that returns a pair of random numbers representing the particle position.\n",
    "\n",
    "The position can be retrieved from the attribute `.position` of the generated image. `.properties` contains a list of all properties used to create the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate particle with random position\n",
    "\n",
    "point_particle_with_random_position = PointParticle(                                         \n",
    "    intensity=100,\n",
    "    position=lambda: 10 + np.random.rand(2) * 44,\n",
    "    position_unit=\"pixel\"\n",
    ")\n",
    "\n",
    "imaged_particle_with_random_position = optics(point_particle_with_random_position)\n",
    "\n",
    "input_image = np.zeros((64, 64))\n",
    "output_image = imaged_particle_with_random_position.resolve(input_image)\n",
    "\n",
    "plt.imshow(output_image, cmap='gray')\n",
    "\n",
    "\n",
    "# Retrieve particle position\n",
    "\n",
    "def get_position_of_particle(image):\n",
    "    for image_property in image.properties:\n",
    "        if \"position\" in image_property:\n",
    "            return image_property[\"position\"]\n",
    "\n",
    "position_of_particle = get_position_of_particle(output_image)\n",
    "\n",
    "plt.scatter(position_of_particle[0], position_of_particle[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Define the neural network model\n",
    "\n",
    "We will use a predefined neural network model to track the particle obtained by calling the function `convolutional`. This model is a convolutional neural network with a dense top. It receives an input of shape (64, 64, 1) and outputs two values (x and y position of the particle)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = convolutional(\n",
    "    input_shape=(64, 64, 1), \n",
    "    number_of_outputs=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Define image generator\n",
    "\n",
    "Generators are objects that feed models with images and their corresponging labels during training. They are created by calling `.generate()` on an instance of the class Generator. This method takes the following inputs:\n",
    "* feature: A feature that resolves images used to train a model\n",
    "* label_function: A function that takes an image as input and returns the label for that image\n",
    "* shape: The shape of the output image\n",
    "* batch_size: The number of images per batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that retireves the position of a particle \n",
    "# and divides it by 64 to get values between 0 and 1\n",
    "def get_scaled_position_of_particle(image):\n",
    "    position_of_particle = get_position_of_particle(image)\n",
    "    return position_of_particle / 64\n",
    "\n",
    "generator = Generator().generate(\n",
    "    particle, \n",
    "    get_position_of_particle, \n",
    "    shape=(64, 64), \n",
    "    batch_size=4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Train the model\n",
    "\n",
    "The model is trained by calling `.fit()` with the generator we defined in the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    generator,\n",
    "    epochs=1000,\n",
    "    steps_per_epoch=64\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Visualize the model performance\n",
    "\n",
    "We can now use the trained model to measure the particle position in images previously unseen by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, real_positions = next(generator)\n",
    "\n",
    "mesured_positions = model.predict(images)\n",
    "\n",
    "for i in range(images.shape[0]):\n",
    "    \n",
    "    image = np.squeeze(images[i])\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    \n",
    "    mesured_position_x = prediction[i, 0] * 64\n",
    "    mesured_position_y = prediction[i, 1] * 64    \n",
    "    plt.scatter(mesured_position_x, mesured_position_y)\n",
    "    \n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
