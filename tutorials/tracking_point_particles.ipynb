{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# deeptrack - Tracking point particles\n",
    "\n",
    "This notebook demonstrates how to track point particles with a convolutional neural network using DeepTrack.\n",
    "\n",
    "The examples gives a general overview of how to: \n",
    "* Define image generation\n",
    "* Extract information from an image to use as labels\n",
    "* Define and train a model\n",
    "* Visually evaluate the result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "Imports needed for this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deeptrack.scatterers import PointParticle\n",
    "from deeptrack.optics import OpticalDevice\n",
    "from deeptrack.generators import Generator\n",
    "from deeptrack.models import convolutional\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define the particle\n",
    "\n",
    "For this example, we consider a point particle (i.e. a point light source). A point particle is entirely defined by its intensity and its position. A point particle is an instance of the class PointParticle.\n",
    "\n",
    "A point particle is controlled by the following parameters:\n",
    "\n",
    "* intensity: The intensity of the point particle\n",
    "\n",
    "* position: The position of the point particle\n",
    "\n",
    "* position_unit: \"pixel\" or \"meter\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "particle = PointParticle(                                         \n",
    "    intensity=100,\n",
    "    position=(32, 16),\n",
    "    position_unit=\"pixel\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define the optics \n",
    "\n",
    "Next, we need to define the properties of the optical system. This is done using an instance of the class Optics, which takes a set of light sources (particles) and convolves them with the pupil function (point spread function) of the otical system.\n",
    "\n",
    "The optics is controlled by the following parameters:\n",
    "\n",
    "* NA: The numerical aperature\n",
    "\n",
    "* pixel_size: The pixel to meter conversion factor (m/px)\n",
    "\n",
    "* wavelength: The wavelength of the lightsource (m)\n",
    "\n",
    "* mode: \"coherent\" or \"incoherent\" light emitted by the object\n",
    "\n",
    "* ROI: Region of interest that is imaged (to avoid wrap-around effects when Fourier-tranforming)\n",
    "\n",
    "* upscale: upscale factor for the pupil function (increases accuracy and computational cost)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optics = OpticalDevice(\n",
    "    NA=0.7,                \n",
    "    pixel_size=0.1e-6,     \n",
    "    wavelength=680e-9\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Generate and plot the image\n",
    "\n",
    "Finally, we have everything needed to create an image! \n",
    "\n",
    "To image something through an optical device, we call the optical device with the object we want to image (here, the feature particle). This returns a new object that resolves images of the object imaged through the optical device.\n",
    "\n",
    "To visualize the image the neural network will see, we can call the method `.plot()`. This will resolve an image of shape (128, 128) and plot it using matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imaged_particle = optics(particle)\n",
    "\n",
    "output_image = imaged_particle.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Randomize the particle position\n",
    "\n",
    "We can generate particles with random positions by passing a lambda function to the keyword argument `position`. \n",
    "When this lambda function is called, it returns a random pair of numbers representing the particle position. \n",
    "\n",
    "In the example below, we also plot the position of the particle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieves the current position of the particle\n",
    "def get_position():\n",
    "    return np.array(particle.properties[\"position\"].current_value)\n",
    "\n",
    "particle = PointParticle(                                         \n",
    "    intensity=100,\n",
    "    position=lambda: 10 + np.random.rand(2) * 44,\n",
    "    position_unit=\"pixel\"\n",
    ")\n",
    "\n",
    "input_image = np.zeros((64, 64))\n",
    "\n",
    "imaged_particle = optics(particle)\n",
    "output_image = imaged_particle.resolve(input_image)\n",
    "\n",
    "position = get_position()\n",
    "plt.gray()\n",
    "plt.imshow(output_image)\n",
    "plt.scatter(position[0], position[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Define the model\n",
    "\n",
    "We will use a predefined keras model to track the particle. This model is a convolutional network with a dense top. It recieves an input of shape (64, 64, 1) and outputs two values, interpereted as the x and y position of the particle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = convolutional(input_shape=(64, 64, 1), number_of_outputs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Define an image generator\n",
    "\n",
    "Generators are objects that feed keras models with images and their corresponging labels during training. They are created by calling `.generate()` on a Generator instance. This method takes the following inputs:\n",
    "* feature: A feature that resolves images used to train a model\n",
    "* label_function: A function that takes an image as input and returns the label for that image\n",
    "* shape: The shape of the output image\n",
    "* batch_size: The number of images per batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide position by 64 to get value between 0 and 1\n",
    "def get_position(image):\n",
    "    return np.array(particle.properties[\"position\"].current_value / 64)\n",
    "\n",
    "generator = Generator().generate(imaged_particle, get_position, shape=(64, 64), batch_size=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Train the model\n",
    "\n",
    "Keras models are trained by calling `.fit()` with the generator we defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    generator,\n",
    "    epochs=1000,\n",
    "    steps_per_epoch=64\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Visualize the model accuracy\n",
    "\n",
    "To visualize the accuracy of the model, we generate a batch by calling `next()` on the generator and predicting the position using the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch, label = next(generator)\n",
    "\n",
    "# prediction = model.predict(batch)\n",
    "\n",
    "for i in range(batch.shape[0]):\n",
    "    plt.gray()\n",
    "    plt.imshow(np.squeeze(batch[i]))\n",
    "    # Multiply back 64\n",
    "#     plt.scatter(prediction[i,0] * 64, prediction[i,1] * 64)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
