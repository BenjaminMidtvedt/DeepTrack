{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "sys.path.append(\"..\") # Adds the module to path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepTrack\n",
    "\n",
    "This notebook gives an overview of the capabilities of DeepTrack and how to model optical systems using predifined classes.\n",
    "\n",
    "### What is DeepTrack?\n",
    "\n",
    "DeepTrack is fundamentally permits to create, train and execute particle tracking models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generate images\n",
    "\n",
    "A central capability is to generate images, which can be used to train and validate the operation of particle tracking models. For example, these images may be like the output of optical systems employed in experiments. \n",
    "\n",
    "The main idea of DeepTrack is that any image can be viewed as a series of features. These features take an input image and update it according to some update rule. For example, a feature can add a particle, introduce some noise, or image something through an optical device."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features and properties\n",
    "\n",
    "Features in DeepTrack are classes implementing the class `Feature`. The way a feature updates an image is governed by the values passed to the class constructor. These inputs are converted to [properties](../examples/properties_example.ipynb). For example, a property could be the position of a particle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deeptrack.scatterers import PointParticle\n",
    "\n",
    "particle = PointParticle(\n",
    "    position=(0, 0),\n",
    "    intensity=100,\n",
    "    position_unit=\"pixel\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code creates a feature (a point particle). This feature will always add a point particle at x=0, y=0. For machine learning, it may be more useful to add a particle at a random position. Thsi can be done by passing a lambda function that returns a random pair of numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "particle = PointParticle(\n",
    "    position=lambda: np.random.rand(2) * 64,\n",
    "    position_unit=\"pixel\",\n",
    "    intensity=100\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resolving an image\n",
    "\n",
    "To create an image from a feature, just call its method `.resolve()` with an empty ndarray (all elements zero). To update the properties (here, generating a new random position), call the method `.update()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "input_image = np.zeros((64, 64))\n",
    "\n",
    "# Generate a new random position\n",
    "particle.update()\n",
    "\n",
    "# Add the particle to the image\n",
    "output_image = particle.resolve(input_image)\n",
    "\n",
    "plt.imshow(output_image, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the output doesn't look much like a point scatterer. This is because it's not imaged through an optical device. \n",
    "\n",
    "Optical devices are also features. They convolve the input image with a pupil function. They also pass optical properties to the features used to generate their input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deeptrack.optics import OpticalDevice\n",
    "\n",
    "optics = OpticalDevice(\n",
    "    NA=0.8,\n",
    "    wavelength=680e-9,\n",
    "    pixel_size=100e-9\n",
    ")\n",
    "\n",
    "# To image a feature, call optics with the feature\n",
    "imaged_particle = optics(particle)\n",
    "\n",
    "imaged_particle.update()\n",
    "\n",
    "output_image = imaged_particle.resolve(input_image)\n",
    "\n",
    "plt.imshow(output_image, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "#TODO: Not sure how .update() works. Even if I remove it from this cell, it still updates the particle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding more features\n",
    "\n",
    "Features can be combined (see [features_example](../examples/features_example.ipynb)) using overloaded operators (+, \\*, \\*\\* or ()). Here, we exemplify the add operator (+) and the power opertor (\\*\\*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The + operator\n",
    "particle_1 = PointParticle(\n",
    "    position=lambda: np.random.rand(2) * 64,\n",
    "    position_unit=\"pixel\",\n",
    "    intensity=100\n",
    ")\n",
    "\n",
    "particle_2 = PointParticle(\n",
    "    position=lambda: np.random.rand(2) * 64,\n",
    "    position_unit=\"pixel\",\n",
    "    intensity=100\n",
    ")\n",
    "\n",
    "# two_particles is a new feature that first resolves particle_1 and then particle_2, then images it\n",
    "two_particles = optics(particle_1 + particle_2)\n",
    "\n",
    "output_image = two_particles.resolve(input_image)\n",
    "\n",
    "plt.imshow(output_image, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The ** operator\n",
    "\n",
    "particle = PointParticle(\n",
    "    position=lambda: np.random.rand(2) * 64,\n",
    "    position_unit=\"pixel\",\n",
    "    intensity=100\n",
    ")\n",
    "\n",
    "# five_particles is a feature that resolves five deep copies of particle, then images it\n",
    "five_particles = optics(particle**5)\n",
    "\n",
    "output_image = five_particles.resolve(input_image)\n",
    "\n",
    "plt.imshow(output_image, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero-padding the input\n",
    "\n",
    "You may have noticed that particles close to edges wrap around to the other side. This is due to the wrap-around effect of the Fourier transform used when convolving an image with a pupil. To solve this problem, we zero-pad the input. The desired size can be retrieved in the optics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optics = OpticalDevice(\n",
    "    NA=0.8,\n",
    "    wavelength=680e-9,\n",
    "    pixel_size=100e-9,\n",
    "    ROI = (0, 0, 64, 64) # row, column, height, width\n",
    ")\n",
    "\n",
    "five_particles = optics(particle**5)\n",
    "\n",
    "# Input a slightly larger image as zero padding\n",
    "input_image = np.zeros((96, 96))\n",
    "\n",
    "output_image = five_particles.resolve(input_image)\n",
    "\n",
    "plt.imshow(output_image, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding noise\n",
    "\n",
    "To make the image more realistic, we can add some noise. Noise can be added before (most commonly) or after applying the optical device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deeptrack.noises import Offset, Poisson\n",
    "\n",
    "# Add a constant value to the background\n",
    "offset = Offset(offset=10)\n",
    "\n",
    "# Introduce Poisson noise to the image\n",
    "poisson_noise = Poisson(snr=100)\n",
    "\n",
    "# resolve five particles, add a offset, image it, and finally introduce Poisson noise\n",
    "noisy_particles = optics(particle**5 + offset) + poisson_noise\n",
    "\n",
    "output_image = noisy_particles.resolve(input_image)\n",
    "\n",
    "plt.imshow(output_image, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Retrieve information about the image\n",
    "\n",
    "To train a supervised machine-learning model, labled images are needed. When a features is resolved, it automatically stores the properties of all features used to create the image. This allows us to extract information about the image in order to use them to train machine-learning models.\n",
    "\n",
    "Here, we extract the position of all the particles and plot them as red crossed on the generated image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_positions(image):\n",
    "    # All properties are stored in the `properties` field of the output.\n",
    "    positions = [property_dict[\"position\"] for property_dict in image.properties if \"position\" in property_dict]\n",
    "    return np.array(positions)\n",
    "\n",
    "\n",
    "noisy_particles.update()\n",
    "output_image = noisy_particles.resolve(input_image)\n",
    "\n",
    "positions = get_positions(output_image)\n",
    "\n",
    "plt.imshow(output_image, cmap='gray')\n",
    "plt.scatter(positions[:, 0], positions[:, 1], c=\"r\", marker=\"x\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Wrap features in generators\n",
    "\n",
    "Generators are ways to continuously resolve new images, and are the prefered interface to machine learning models. The default generator is defined in the module `generators`. We can also optionally pass a label function that will be called on every image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deeptrack.generators import Generator\n",
    "\n",
    "generator = Generator().generate(noisy_particles, get_positions, shape=(96, 96))\n",
    "\n",
    "for _ in range(4):\n",
    "    # Outputs shape (1, height, width, 1)\n",
    "    next_image, positions = next(generator)\n",
    "    plt.imshow(np.squeeze(next_image), cmap='gray')\n",
    "    plt.scatter(positions[0, :, 0], positions[0, :, 1], c=\"r\", marker=\"x\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Finally, a complete example that also trains a neural-network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deeptrack.scatterers import PointParticle\n",
    "from deeptrack.noises import Offset, Poisson\n",
    "from deeptrack.optics import OpticalDevice\n",
    "from deeptrack.generators import Generator\n",
    "from deeptrack.models import convolutional\n",
    "\n",
    "# DEFINE FEATURES\n",
    "optics = OpticalDevice(NA=0.8, wavelength=680e-9, pixel_size=100e-9, ROI=(0, 0, 64, 64))\n",
    "\n",
    "particle = PointParticle(\n",
    "    position=lambda: np.random.rand(2) * 64,\n",
    "    position_unit=\"pixel\",\n",
    "    intensity=100\n",
    ")\n",
    "\n",
    "offset = Offset(\n",
    "    offset = lambda: np.random.rand() * 20\n",
    ")\n",
    "\n",
    "poisson_noise = Poisson(snr=np.linspace(50, 100))\n",
    "\n",
    "training_set = optics(particle + offset) + poisson_noise\n",
    "\n",
    "\n",
    "# DEFINE LABEL FUNCTION\n",
    "def get_position(image):\n",
    "    for propertydict in image.properties:\n",
    "        if \"position\" in propertydict:\n",
    "            return propertydict[\"position\"] / 64\n",
    "        \n",
    "# DEFINE MODEL\n",
    "tracker = convolutional(input_shape=(64, 64, 1), number_of_outputs=2)\n",
    "\n",
    "# DEFINE GENERATOR\n",
    "generator = Generator().generate(training_set, get_position, shape=(96, 96), batch_size=32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN TRACKER\n",
    "tracker.fit(generator, epochs=100, steps_per_epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch, labels = next(generator)\n",
    "predictions = tracker.predict(batch) * 64\n",
    "for image, position, prediction in zip(batch, labels, predictions):\n",
    "    plt.imshow(image[:, :, 0], cmap='gray')\n",
    "    plt.scatter(position[0], position[1], c='g', marker='x')\n",
    "    plt.scatter(prediction[0], prediction[1], marker='o', facecolors=None, edgecolors='b')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
